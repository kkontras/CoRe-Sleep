{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import sys\n",
    "\n",
    "import einops\n",
    "import numpy\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.exc_info()\n",
    "from utils.config import process_config\n",
    "from datasets.sleepset import *\n",
    "from graphs.models.attention_models.windowFeature_base import *\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.deterministic_pytorch import deterministic\n",
    "# import umap\n",
    "from scipy.stats import entropy\n",
    "import os\n",
    "from torchdistill.core.forward_hook import ForwardHookManager\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Loading\n"
     ]
    }
   ],
   "source": [
    "def sleep_load_encoder(encoders):\n",
    "    encs = []\n",
    "    for num_enc in range(len(encoders)):\n",
    "        if encoders[num_enc][\"model\"] == \"TF\":\n",
    "            layers = [\"huy_pos_inner\", \"inner_att\", \"aggregation_att_contx_inner\", \"huy_pos_outer\", \"outer_att\"]\n",
    "            enc = Multi_Transformer(128, inner= 29, outer = 21, modalities=1, heads=8,\n",
    "                                 layers = layers, num_layers=4, pos = False)\n",
    "        else:\n",
    "            enc_class = globals()[encoders[num_enc][\"model\"]]\n",
    "            args = encoders[num_enc][\"args\"]\n",
    "            enc = enc_class(args = args)\n",
    "            enc = nn.DataParallel(enc, device_ids=[torch.device(0)])\n",
    "\n",
    "        if encoders[num_enc][\"pretrainedEncoder\"][\"use\"]:\n",
    "            print(\"Loading encoder from {}\".format(encoders[num_enc][\"pretrainedEncoder\"][\"dir\"]))\n",
    "            checkpoint = torch.load(encoders[num_enc][\"pretrainedEncoder\"][\"dir\"])\n",
    "            enc.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
    "        encs.append(enc)\n",
    "    return encs\n",
    "\n",
    "def load_models(config, device, checkpoint, only_model=False):\n",
    "\n",
    "    model_class = globals()[config.model.model_class]\n",
    "    # config.pretrainedEncoder = [False]\n",
    "    enc = sleep_load_encoder(encoders=config.model.encoders)\n",
    "    model = model_class(enc, args = config.model.args)\n",
    "    # model = model.to('cpu')\n",
    "    # model = nn.DataParallel(model, device_ids='cpu')\n",
    "    model = model.to(device)\n",
    "    model = nn.DataParallel(model, device_ids=[torch.device(i) for i in config.gpu_device])\n",
    "\n",
    "    #\n",
    "    if only_model:\n",
    "        return model\n",
    "\n",
    "    # config.pretrainedEncoder = [True]\n",
    "    # enc = sleep_load_encoder(encoder_models=config.encoder_models,pretrainedEncoder=config.pretrainedEncoder,save_dir_encoder=config.savetrainedEncoder)\n",
    "    # best_model = model_class(enc, channel = config.channel)\n",
    "    # best_model = best_model.to(device)\n",
    "    # best_model = nn.DataParallel(best_model, device_ids=[torch.device(i) for i in config.gpu_device])\n",
    "\n",
    "    best_model = copy.deepcopy(model)\n",
    "    # best_model = best_model.to('cpu')\n",
    "    # best_model = nn.DataParallel(best_model, device_ids='cpu')\n",
    "    # model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    best_model.load_state_dict(checkpoint[\"best_model_state_dict\"])\n",
    "\n",
    "    return model, best_model\n",
    "\n",
    "def find_patient_list(data_loader):\n",
    "    patient_list = [int(data.split(\"/\")[-1][1:5]) for data in data_loader.dataset.dataset[0] if data.split(\"/\")[-1]!=\"empty\"]\n",
    "    return patient_list\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for i in range(len(y_hat)):\n",
    "        if y_actual[i] == y_hat[i] == 1:\n",
    "            TP += 1\n",
    "        if y_hat[i] == 1 and y_actual[i] != y_hat[i]:\n",
    "            FP += 1\n",
    "        if y_actual[i] == y_hat[i] == 0:\n",
    "            TN += 1\n",
    "        if y_hat[i] == 0 and y_actual[i] != y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return (TP, FP, TN, FN)\n",
    "\n",
    "def print_perf(model_name, patient_num, preds, tts, multiclass=True):\n",
    "    preds_eeg = preds.argmax(-1)\n",
    "    test_acc = np.equal(tts, preds_eeg).sum() / len(tts)\n",
    "    test_f1 = f1_score(preds_eeg, tts) if not multiclass else f1_score(preds_eeg, tts, average=\"macro\")\n",
    "    test_perclass_f1 = f1_score(preds_eeg, tts) if not multiclass else f1_score(preds_eeg, tts, average=None)\n",
    "    test_k = cohen_kappa_score(tts, preds_eeg)\n",
    "    test_auc = roc_auc_score(tts, preds_eeg) if not multiclass else 0\n",
    "    test_conf = confusion_matrix(tts, preds_eeg)\n",
    "    tp, fp, tn, fn = perf_measure(tts, preds_eeg)\n",
    "    test_spec = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    test_sens = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    print(\"{} Patient {} has acc: {}, f1: {}, k:{} and f1_per_class: {}\".format(model_name, patient_num,\n",
    "                                                                             round(test_acc * 100, 1),\n",
    "                                                                             round(test_f1 * 100, 1),\n",
    "                                                                             round(test_k, 3),\n",
    "                                                                             np.round(test_perclass_f1 * 100,\n",
    "                                                                                      1)))\n",
    "    return test_k\n",
    "\n",
    "def get_performance_windows(preds, tts, print_it=True, window=40):\n",
    "    tts_unfolded = torch.from_numpy(tts).unfold(0, window, window).numpy()\n",
    "    preds_unfolded = torch.from_numpy(preds).unfold(0, window, window).numpy()\n",
    "    perf_window = np.array([np.equal(tts_unfolded[i], preds_unfolded[i]).sum() / len(tts_unfolded[i]) for i in range(tts_unfolded.shape[0])])\n",
    "    perf_window[perf_window != perf_window] = 1\n",
    "    if print_it:\n",
    "        for i in perf_window: print(\"{:.3f}\".format(i), end=\" \")\n",
    "        print()\n",
    "    perf_window = perf_window\n",
    "    return perf_window\n",
    "\n",
    "def get_windows(input, window=40):\n",
    "    input_unfolded = torch.from_numpy(input).unfold(0, window, window).numpy()\n",
    "    if (input_unfolded != input_unfolded).any(): print(\"Î¤here are nan\")\n",
    "    input_unfolded = input_unfolded.mean(axis=-1)\n",
    "    # input_unfolded = input_unfolded.repeat(window)\n",
    "    return input_unfolded\n",
    "\n",
    "def change_numbers_preds(preds, tts, argmax=True):\n",
    "    if argmax: pred_plus = copy.deepcopy(preds).argmax(-1)\n",
    "    else: pred_plus = copy.deepcopy(preds)\n",
    "    pred_plus[pred_plus == 4] = 5\n",
    "    pred_plus[pred_plus == 3] = 4\n",
    "    pred_plus[pred_plus == 2] = 3\n",
    "    pred_plus[pred_plus == 5] = 2\n",
    "\n",
    "    target_plus = copy.deepcopy(tts)\n",
    "    target_plus[target_plus == 4] = 5\n",
    "    target_plus[target_plus == 3] = 4\n",
    "    target_plus[target_plus == 2] = 3\n",
    "    target_plus[target_plus == 5] = 2\n",
    "\n",
    "    return pred_plus, target_plus\n",
    "\n",
    "def find_matches(pred_plus, target_plus):\n",
    "\n",
    "    non_matches = (pred_plus != target_plus).astype(int)\n",
    "    non_matches_idx = non_matches.nonzero()[0]\n",
    "    return non_matches_idx\n",
    "\n",
    "def print_max_perf(predictors, performs, tts, window_floor):\n",
    "    max_preds = []\n",
    "    for i in range(len(performs[0])):\n",
    "        max_mod = np.argmax(np.array([perf[i] for perf in performs]))\n",
    "        max_preds.append(predictors[max_mod][i*window_floor:(i+1)*window_floor])\n",
    "    max_preds = np.array(max_preds).flatten()\n",
    "\n",
    "    multiclass = True\n",
    "    model_name = \"Max\"\n",
    "    test_acc = np.equal(tts, max_preds).sum() / len(tts)\n",
    "    test_f1 = f1_score(max_preds, tts) if not multiclass else f1_score(max_preds, tts, average=\"macro\")\n",
    "    test_perclass_f1 = f1_score(max_preds, tts) if not multiclass else f1_score(max_preds, tts, average=None)\n",
    "    test_k = cohen_kappa_score(tts, max_preds)\n",
    "    test_auc = roc_auc_score(tts, max_preds) if not multiclass else 0\n",
    "    test_conf = confusion_matrix(tts, max_preds)\n",
    "    tp, fp, tn, fn = perf_measure(tts, max_preds)\n",
    "    test_spec = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    test_sens = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    print(\"{} Patient {} has acc: {}, f1: {}, k:{} and f1_per_class: {}\".format(model_name, patient_num,\n",
    "                                                                             round(test_acc * 100, 1),\n",
    "                                                                             round(test_f1 * 100, 1),\n",
    "                                                                             round(test_k, 3),\n",
    "                                                                             np.round(test_perclass_f1 * 100,\n",
    "                                                                                      1)))\n",
    "    return test_k, max_preds\n",
    "\n",
    "print(\"Done Loading\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "multimodal_config_name = \"./configs/shhs/multi_modal/eeg_eog/established_models/fourier_transformer_eeg_eog_mat_BIOBLIP_lossw.json\"\n",
    "eeg_config_name = \"./configs/shhs/single_channel/fourier_transformer_cls_eeg_mat_adv.json\"\n",
    "eog_config_name = \"./configs/shhs/single_channel/fourier_transformer_cls_eog_mat.json\"\n",
    "emg_config_name = \"./configs/shhs/single_channel/fourier_transformer_cls_emg_mat.json\"\n",
    "router_config_name = \"./configs/shhs/router/router_fourier_tf_eeg_eog.json\"\n",
    "\n",
    "multimodal_config = process_config(multimodal_config_name, False)\n",
    "eeg_config = process_config(eeg_config_name, False)\n",
    "eog_config = process_config(eog_config_name, False)\n",
    "emg_config = process_config(emg_config_name, False)\n",
    "router_config = process_config(router_config_name, False)\n",
    "\n",
    "multimodal_config.data_view_dir = [\n",
    "            {\"list_dir\" : \"patient_mat_list.txt\", \"data_type\": \"stft\", \"mod\": \"eeg\", \"num_ch\": 1},\n",
    "            {\"list_dir\" :\"patient_eog_mat_list.txt\", \"data_type\": \"stft\", \"mod\": \"eog\", \"num_ch\": 1},\n",
    "            {\"list_dir\" :\"patient_emg_mat_list.txt\", \"data_type\": \"stft\", \"mod\": \"emg\", \"num_ch\": 1},\n",
    "            {\"list_dir\" : \"patient_mat_list.txt\", \"data_type\": \"time\", \"mod\": \"eeg\", \"num_ch\": 1},\n",
    "            {\"list_dir\" : \"patient_eog_mat_list.txt\", \"data_type\": \"time\", \"mod\": \"eog\", \"num_ch\": 1},\n",
    "            {\"list_dir\" : \"patient_emg_mat_list.txt\", \"data_type\": \"time\", \"mod\": \"emg\", \"num_ch\": 1}\n",
    "        ]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are splitting dataset by huy splits\n",
      "True\n",
      "We are loading weights\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "#Load the models\n",
    "checkpoint_multimodal = torch.load(multimodal_config.model.save_dir, map_location=\"cpu\")\n",
    "checkpoint_eeg = torch.load(eeg_config.model.save_dir, map_location=\"cpu\")\n",
    "checkpoint_eog = torch.load(eog_config.model.save_dir, map_location=\"cpu\")\n",
    "checkpoint_emg = torch.load(emg_config.model.save_dir, map_location=\"cpu\")\n",
    "checkpoint_router = torch.load(router_config.model.save_dir, map_location=\"cpu\")\n",
    "dataloader = globals()[multimodal_config.dataloader_class]\n",
    "data_loader = dataloader(config=multimodal_config)\n",
    "data_loader.load_metrics_ongoing(checkpoint_multimodal[\"metrics\"])\n",
    "data_loader.weights = checkpoint_multimodal[\"logs\"][\"weights\"]\n",
    "_, best_model_multimodal = load_models(config=multimodal_config, device=device, checkpoint=checkpoint_multimodal)\n",
    "_, best_model_eeg = load_models(config=eeg_config, device=device, checkpoint=checkpoint_eeg)\n",
    "_, best_model_eog = load_models(config=eog_config, device=device, checkpoint=checkpoint_eog)\n",
    "_, best_model_emg = load_models(config=emg_config, device=device, checkpoint=checkpoint_emg)\n",
    "router_model  = load_models(config=router_config, device=device, checkpoint=checkpoint_emg, only_model=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "router_model.train()\n",
    "start = time.time()\n",
    "\n",
    "tts, preds, batch_loss, early_stop = [], [], [], False\n",
    "saved_at_step, prev_epoch_time = 0, 0\n",
    "for logs[\"current_epoch\"] in range(logs[\"current_epoch\"], router_config.max_epoch):\n",
    "    pbar = tqdm(enumerate(data_loader.train_loader), desc=\"Training\", leave=None, disable=router_config.tdqm_disable, position=0)\n",
    "    for batch_idx, batch in pbar:\n",
    "        data, target, inits = batch[0], batch[1], batch[2]\n",
    "\n",
    "        data = [data[i].float().cuda() for i in range(len(data))]\n",
    "\n",
    "        if \"softlabels\" in router_config.config and router_config.config.softlabels:\n",
    "            target = target.float().cuda()\n",
    "        else:\n",
    "            target = target.cuda().flatten(start_dim=0, end_dim=1).long()\n",
    "            if len(target.shape) > 1:\n",
    "                target = target.argmax(dim=1).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, pred = self.this_train_step_func(data, target, inits, teacher_preds)\n",
    "        # torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n",
    "        optimizer.step()\n",
    "        scheduler.step(logs[\"current_step\"]+1)\n",
    "        # if \"sparse_loss\" in self.config and self.config.sparse_loss:\n",
    "        # loss, pred = self.sleep_train_one_step_sparse(data, target, inits)\n",
    "\n",
    "        batch_loss.append(loss)\n",
    "        tts.append(target)\n",
    "        preds.append(pred)\n",
    "\n",
    "        del data, target, pred, loss\n",
    "\n",
    "        pbar_message = Fore.WHITE + \"Training batch {0:d}/{1:d} steps no improve {2:d} with \".format(batch_idx, len(self.agent.data_loader.train_loader)-1, self.agent.logs[\"steps_no_improve\"])\n",
    "        mean_batch = self._calc_mean_batch_loss(batch_loss=batch_loss)\n",
    "        for mean_key in mean_batch: pbar_message += \"{}: {:.3f} \".format(mean_key, mean_batch[mean_key])\n",
    "\n",
    "        if logs[\"current_step\"] % router_config.validate_every == 0 and \\\n",
    "            logs[\"current_step\"] // router_config.validate_every >= router_config.validate_after and \\\n",
    "            batch_idx!=0:\n",
    "            early_stop = monitor_n_saver.checkpointing(batch_loss = mean_batch, predictions = preds, targets = tts)\n",
    "            batch_loss, tts, preds = [], [], []\n",
    "\n",
    "            if early_stop: break\n",
    "            saved_at_step = logs[\"current_step\"] // router_config.validate_every\n",
    "            prev_epoch_time = time.time() - self.agent.start\n",
    "            self.start = time.time()\n",
    "\n",
    "        pbar_message += \" time {:.1f} sec/step, \".format(prev_epoch_time)\n",
    "        pbar_message += \"saved at {}\".format(saved_at_step)\n",
    "        pbar.set_description(pbar_message)\n",
    "        pbar.refresh()\n",
    "        self.agent.logs[\"current_step\"] += 1\n",
    "\n",
    "            return_matches= True if self.w_loss[\"alignments\"]!=0 else False\n",
    "            return_order= True if self.w_loss[\"order\"]!=0 else False\n",
    "\n",
    "            # pred, matches = self.get_predictions_time_series_alignment(views, inits)\n",
    "            output = self.agent.model(data, return_matches=return_matches, return_order=return_order)\n",
    "\n",
    "            teacher_preds = teacher_preds.to(self.agent.device).flatten(start_dim=0, end_dim=1)  if \"kd_label\" in self.agent.config and self.agent.config.kd_label else None\n",
    "            ce_loss = {}\n",
    "            for k, v in output[\"preds\"].items():\n",
    "                ce_loss[k] = self.agent.loss(v, target, teacher_preds) if teacher_preds else self.agent.loss(v, target)\n",
    "\n",
    "            total_loss = 0\n",
    "            output_losses = {}\n",
    "            for i in ce_loss:\n",
    "                total_loss += self.w_loss[i] * ce_loss[i]\n",
    "                ce_loss[i] = ce_loss[i].detach().cpu().numpy()\n",
    "                output_losses.update({\"ce_loss_{}\".format(i): ce_loss[i]})\n",
    "\n",
    "            if return_matches:\n",
    "                matches = output[\"matches\"].flatten(start_dim=0, end_dim=1).flatten(start_dim=1)\n",
    "                if \"blip_loss\" in self.agent.config:\n",
    "                    alignment_target = self.agent.alignment_target[:data[0].shape[0], :data[0].shape[1], :data[0].shape[1]].flatten(start_dim=0, end_dim=1)\n",
    "                else:\n",
    "                    alignment_target = self.agent.alignment_target[:data[0].shape[0], :data[0].shape[1]].flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "                alignment_loss = self.agent.alignment_loss(matches, alignment_target)\n",
    "                total_loss += self.w_loss[\"alignments\"]*alignment_loss\n",
    "                alignment_loss = alignment_loss.detach().cpu().numpy()\n",
    "                output_losses.update({\"alignment_loss\": alignment_loss})\n",
    "\n",
    "            if return_order:\n",
    "                unfolded_target = einops.rearrange(target,\" (b outer) -> b outer\", b=data[0].shape[0], outer=data[0].shape[1])\n",
    "                unfolded_target = unfolded_target.unfold(1,3,1)\n",
    "                same_label_left = unfolded_target[:, :, 0] == unfolded_target[:, :, 1]\n",
    "                same_label_right = unfolded_target[:, :, 2] == unfolded_target[:, :, 1]\n",
    "\n",
    "                order_target = torch.zeros([data[0].shape[0], data[0].shape[1]-2]).cuda() != 0 #Initially everything is False\n",
    "                order_target[same_label_left] = same_label_right[same_label_left] == True #If the ones that are left are True, index right and take only the True ones from that.\n",
    "\n",
    "                order_target = order_target.flatten().long()\n",
    "                order_loss = self.agent.order_loss(output[\"order\"], order_target)\n",
    "                total_loss += self.w_loss[\"order\"]*order_loss\n",
    "                order_loss = order_loss.detach().cpu().numpy()\n",
    "                output_losses.update({\"order_loss\": order_loss})\n",
    "\n",
    "\n",
    "            total_loss.backward()\n",
    "\n",
    "            total_loss =  total_loss.detach().cpu().numpy()\n",
    "            output_losses.update({\"total\": total_loss})\n",
    "\n",
    "            for i in output[\"preds\"]:  output[\"preds\"][i] =  output[\"preds\"][i].detach().cpu().numpy()\n",
    "\n",
    "            return output_losses, output[\"preds\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}